{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.1 Metadata Acquistion - MARC XML\n",
    "**Process overview:**\n",
    "\n",
    "This process aims at acquiring MARC XML files, import them, get the relevant metadata and convert it to a more suitable structure. It includes the following steps:\n",
    "1. import MARC XML files located in data/acquisition\n",
    "2. gets relevant metadata fields from the XML. Relevant metadata include:\n",
    "    * at least 1 field representing a unique identifier (i.e. MARC field 001, 035, or any relevant local field);\n",
    "    * one or several fields representing the labels, in other words the metadata your institutions wishes to automatically generate;\n",
    "    * metadata fields that could be used to predict the labels (optional)\n",
    "3. create a CSV file and store it in data/pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Libraries required to perform this process\n",
    "# lxml: used to parse and extract data from an XML file\n",
    "from lxml import etree, objectify\n",
    "# Pandas: used to structure metadata as table for better visualization and manipulation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Metadata \n",
    "The following script represent a function that get relevant metadata fields to return a provisional record for further manipulation.\n",
    "\n",
    "Additional lines can be added:\n",
    "\n",
    "<pre><code>\"variable_name\": get_data(r,\"datafield[@tag='MARC_tag'][@ind1='indicator']/subfield[@code='MARC_subfield']\"),</code></pre>\n",
    "\n",
    "* variable_name: report;\n",
    "* a MARC_field: @tag='993'\n",
    "* an indicator: @ind1='3' (optional)\n",
    "* a MARC_subfield: subfield[@code='a']\") (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions needed to acquire MARC XML records and transform them in a more suitable structure\n",
    "def clean_prefixes(xml_root):\n",
    "    '''\n",
    "    This function takes root as argument and clean it from any prefix, before returning it.\n",
    "    '''\n",
    "    for e in xml_root.getiterator():\n",
    "        if hasattr(e.tag, 'find'):\n",
    "            i = e.tag.find('}')\n",
    "            if i >= 0:\n",
    "                e.tag = e.tag[i+1:]\n",
    "    return xml_root\n",
    "\n",
    "def get_metadata(r):\n",
    "    \"\"\"\n",
    "    Takes a MARC XML record. For each metadata, the function will call annother get_element, which will return\n",
    "    'None', a string (one value found), or a list of string (multiple values found)\n",
    "    \"\"\"\n",
    "    # Each record will be a dictionary and include \n",
    "    metadata =  {\n",
    "        # Standard MARC fields\n",
    "        \"record_id\": get_md_value(r,\"controlfield[@tag='001']\"),\n",
    "        \"title\": get_md_value(\n",
    "            r,\"datafield[@tag='245']/subfield[@code='a']\") + \" \" + get_md_value(\n",
    "            r,\"datafield[@tag='245']/subfield[@code='b']\") + \" \" + get_md_value(\n",
    "            r,\"datafield[@tag='245']/subfield[@code='c']\"),\n",
    "        \"topics\": get_md_value(r,\"datafield[@tag='650']/subfield[@code='a']\"),\n",
    "        \"geographic_terms\": get_md_value(r,\"datafield[@tag='651']/subfield[@code='a']\"),\n",
    "        \"corporates\": get_md_value(r,\"datafield[@tag='610']/subfield[@code='a']\"),      \n",
    "        # Local MARC fields in used for UN documents\n",
    "        \"symbol\": get_md_value(r,\"datafield[@tag='191']/subfield[@code='a']\"),\n",
    "        \"body\": get_md_value(r,\"datafield[@tag='191']/subfield[@code='b']\"),\n",
    "        \"session\": get_md_value(r,\"datafield[@tag='191']/subfield[@code='c']\"),\n",
    "    }\n",
    "    return metadata\n",
    "\n",
    "def get_md_value(marc_xml_record,query):\n",
    "    \"\"\"\n",
    "    Takes 2 arguments: a MARC XML record and a query (XPath) that identifies an XML element. \n",
    "    Queries the record to identify the targeted element. If no element is found return 'None', if one element is found returns a string, if more than one\n",
    "    elements are found returns a list of strings.\n",
    "    \"\"\"\n",
    "    # Parse the record to get all matchin gelements\n",
    "    xml_element = marc_xml_record.findall(query)\n",
    "    # Process xml_element according to its length to return either 'None', a string, or a list of strings.\n",
    "    if len(xml_element)>1:\n",
    "        values = []\n",
    "        i = 0\n",
    "        for item in xml_element:\n",
    "            element = values.append(xml_element[i].text)\n",
    "            i +=1\n",
    "        return values\n",
    "    elif len(xml_element) == 1:\n",
    "        return xml_element[0].text\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and parsing XML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a variable with parameters on how the parser should behave.\n",
    "parser = etree.XMLParser(encoding='utf-8')\n",
    "# Import xml file as an xml etree\n",
    "tree = etree.parse('data/acquisition/undl_marc.xml',parser)\n",
    "# Remove prefixes in XML elements\n",
    "root = clean_prefixes(tree.getroot())\n",
    "# Get all <records> element in XML MARC\n",
    "xml_records = root.findall(\"record\")\n",
    "# Get a list of dictionaries containing the metadata specified in the get_metadata function\n",
    "dictionary_records = [get_metadata(r) for r in xml_records]\n",
    "# Create a Pandas data frame\n",
    "md_dataset = pd.DataFrame(dictionary_records).set_index('record_id')\n",
    "# Export to csv in data/pre-processing\n",
    "md_dataset.to_csv('data/pre-processing/mdMARC_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
