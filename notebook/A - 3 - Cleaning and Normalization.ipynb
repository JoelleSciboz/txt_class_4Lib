{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A - 3 - Cleaning and Normalization\n",
    "\n",
    "**Process aim:** cleaning the dataset and reduce it to data used for machine learning.\n",
    "\n",
    "**Input:** a CSV containing metadata and full text\n",
    "\n",
    "**Subprocesses:**\n",
    "* import: importing the dataset\n",
    "* dataset reduction: removing documents (rows) that are missing or have an invalid value\n",
    "* normalization: normalizing so that all values in certain fields have the same format\n",
    "* enrichement: adding some fields based on others\n",
    "* cleaning: removing special characters such as new lines, etc.\n",
    "* subsets: create various subsets from the initial dataset.\n",
    "* saving the output\n",
    "**Output:** CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset\n",
    "We keep only the columns that we will use as/for:\n",
    "* identificator: record_id\n",
    "* labels: columns containing the subjects of the documents (geo, topics) that we want to assign automatically in the future\n",
    "* features: columns containing information we can use to infer the subjects (title, text)\n",
    "* grouping: columns to be used to group subset of documents (symbol, body, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe\n",
    "columns = ['record_id','body', 'symbol', 'title', 'date', 'topics', 'geo','text']\n",
    "dataset = pd.read_csv('../data/A_input/doc_2000_2017_txt.csv', dtype='str', usecols=columns, index_col='record_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['body', 'date', 'geo', 'symbol', 'title', 'topics', 'text'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 151804 entries, 455823 to 247308\n",
      "Data columns (total 7 columns):\n",
      "body      151802 non-null object\n",
      "date      151795 non-null object\n",
      "geo       63147 non-null object\n",
      "symbol    151802 non-null object\n",
      "title     151804 non-null object\n",
      "topics    132022 non-null object\n",
      "text      128144 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 9.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using dataset.info() we can see for each field how many are non-null values. For instance, how many records have subject-topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset reduction\n",
    "Dataset reduction is the process of removing entris (rows) because some fields don't have a valid value. In this case, want to keep only the documents that have a valid value in fields date, symbol, title, and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dataset(dataset,filter_fields):\n",
    "    '''\n",
    "    Takes a list of fields to filter. \n",
    "    For each field, remove the rows that don't have a valid value. \n",
    "    Return the reduce dataset\n",
    "    '''\n",
    "    for field in filter_fields:\n",
    "        dataset = dataset[dataset[field].notnull()]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the fields we want to filter:\n",
    "filter_fields = ['date', 'symbol', 'title', 'text']\n",
    "dataset = reduce_dataset(dataset,filter_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 128144 entries, 455823 to 273481\n",
      "Data columns (total 7 columns):\n",
      "body      128144 non-null object\n",
      "date      128144 non-null object\n",
      "geo       54721 non-null object\n",
      "symbol    128144 non-null object\n",
      "title     128144 non-null object\n",
      "topics    112489 non-null object\n",
      "text      128144 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "### Year\n",
    "To be able to sort and group by date, we need to ensure that the date is normalized and that all rows have a value. We will use only the year instead of the full date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['20011206', '20101004', '20041028', ..., '20000101', '20000213',\n",
       "       '20000316'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['date'] = (dataset.date\n",
    "                   .str.extract('(\\d{4})',expand=False) #  extract the first 4 digits corresponding to the year\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2001', '2010', '2004', '2003', '2000', '2014', '2006', '2005',\n",
       "       '2016', '2015', '2012', '2011', '2009', '2008', '2002', '2013',\n",
       "       '2007', '2017', nan, '1999'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We still find some non-valid values: nan and 1999 (our dataset is supose to cover 2000->)\n",
    "dataset = dataset[dataset['date'].notnull()]\n",
    "dataset = dataset[dataset['date'] != '1999']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Rename column 'date' to year\n",
    "dataset = dataset.rename(columns={'date':'year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 128142 entries, 455823 to 273481\n",
      "Data columns (total 7 columns):\n",
      "body      128142 non-null object\n",
      "year      128142 non-null object\n",
      "geo       54720 non-null object\n",
      "symbol    128142 non-null object\n",
      "title     128142 non-null object\n",
      "topics    112487 non-null object\n",
      "text      128142 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check our dataset to ensure the date field has a value for each record\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Body\n",
    "Annother usefull grouping field is the body. However, there are many different values. We are going to normalize the field so that we keep only the indication of the main UN organ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_body(line):\n",
    "    '''\n",
    "    Clean multiple value cells to return multiple values to return each line:\n",
    "    - fields with multiple values: value one||value two\n",
    "    - fields with a single value: value one\n",
    "    '''\n",
    "    if isinstance(line, str):\n",
    "        line = re.sub(\"(\\*+)|\\'|\\[|\\]|\\s+\",\"\",line)\n",
    "        line = line.split(',')\n",
    "        line = [body.split(\"/\")[0] for body in line]\n",
    "        line = [body for body in line if body in ['A','S','E']]\n",
    "        line = filter(None, line)\n",
    "        line = list(set(line))\n",
    "        line = re.sub(\"(\\*+)|\\'|\\[|\\]|\\s+\",\"\",str(line))\n",
    "        return line\n",
    "    else:\n",
    "        return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['main_body'] = dataset['body'].apply(normalize_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A,S', 'E', 'A', 'S', 'A,E', ''], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.main_body.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the empty values\n",
    "dataset = dataset[dataset['main_body'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A,S', 'E', 'A', 'S', 'A,E'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.main_body.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the body field now that we have a main_body columns\n",
    "dataset = dataset.drop('body', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 128141 entries, 455823 to 273481\n",
      "Data columns (total 7 columns):\n",
      "year         128141 non-null object\n",
      "geo          54719 non-null object\n",
      "symbol       128141 non-null object\n",
      "title        128141 non-null object\n",
      "topics       112486 non-null object\n",
      "text         128141 non-null object\n",
      "main_body    128141 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple values\n",
    "\n",
    "Some columns have multiple values, we want to normalize these columns as follow:\n",
    "* fields with multiple values: value one||value two\n",
    "* fields with a single value: value one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_multiple(line):\n",
    "    '''\n",
    "    Clean multiple value cells to return multiple values to return each line:\n",
    "    - fields with multiple values: value one||value two\n",
    "    - fields with a single value: value one\n",
    "    '''\n",
    "    if isinstance(line, str):\n",
    "        if line.startswith('['):\n",
    "            line = re.sub(\"\\[|\\]\",\"\",line)\n",
    "            line = line.strip(\"'\")\n",
    "            line = line.strip('\"')\n",
    "            line = line.strip(\" \")\n",
    "            line = re.sub(\"('|\\\"),\\s?('|\\\")\",\"||\",line)\n",
    "            return line\n",
    "        else:\n",
    "            line = line.strip(\"'\")\n",
    "            line = line.strip('\"')\n",
    "            line = line.strip(\" \")\n",
    "            line = re.sub(\"\\*\",\"\",line)\n",
    "            return line\n",
    "    else:\n",
    "        return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['geo'] = dataset['geo'].apply(normalize_multiple)\n",
    "dataset['topics'] = dataset['topics'].apply(normalize_multiple)\n",
    "dataset['symbol'] = dataset['symbol'].apply(normalize_multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 128141 entries, 455823 to 273481\n",
      "Data columns (total 7 columns):\n",
      "year         128141 non-null object\n",
      "geo          54719 non-null object\n",
      "symbol       128141 non-null object\n",
      "title        128141 non-null object\n",
      "topics       112486 non-null object\n",
      "text         128141 non-null object\n",
      "main_body    128141 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new columns\n",
    "### Concatenate existing columns\n",
    "Subjects are stored in fields 'topics' and 'geo' (geographical terms). By concatenating both columns, we can create a new field that contains all the label we intend to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_columns(dataset,new_column, column_A, column_B):\n",
    "    '''\n",
    "    Takes a dataset, the name of a new column, and two columns to concatenate\n",
    "    Create the new column, by concatenating columns A and B\n",
    "    Remove invalid strings and values\n",
    "    Return the dataset\n",
    "    '''\n",
    "    dataset[new_column] = (dataset\n",
    "                           .apply(lambda x:'%s||%s' % (x[column_A],x[column_B]),axis=1)\n",
    "                           .apply(lambda x: x.replace('nan||','')) # clean nan strings\n",
    "                           .apply(lambda x: x.replace('||nan','')) # clean nan strings\n",
    "                          )\n",
    "    dataset[new_column] = dataset[new_column].replace('nan',np.nan)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = concatenate_columns(dataset, 'topics_geo', 'topics', 'geo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reduce the dataset so that all documents have at least one label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = reduce_dataset(dataset,['topics_geo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 113483 entries, 455823 to 273481\n",
      "Data columns (total 8 columns):\n",
      "year          113483 non-null object\n",
      "geo           54719 non-null object\n",
      "symbol        113483 non-null object\n",
      "title         113483 non-null object\n",
      "topics        112486 non-null object\n",
      "text          113483 non-null object\n",
      "main_body     113483 non-null object\n",
      "topics_geo    113483 non-null object\n",
      "dtypes: object(8)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting values in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values(values,separator):\n",
    "    if isinstance(values,str):\n",
    "        return len(values.split(separator))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def add_count_fields(dataset, fields):\n",
    "    for field in fields:\n",
    "        dataset[field + '_count'] = (dataset[field].apply(lambda x: count_values(x,'||')))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of fields\n",
    "label_fields = ['geo', 'topics', 'topics_geo']\n",
    "# Add a column that count the number of subjects assigned to each document\n",
    "dataset = add_count_fields(dataset, label_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 113483 entries, 455823 to 273481\n",
      "Data columns (total 11 columns):\n",
      "year                113483 non-null object\n",
      "geo                 54719 non-null object\n",
      "symbol              113483 non-null object\n",
      "title               113483 non-null object\n",
      "topics              112486 non-null object\n",
      "text                113483 non-null object\n",
      "main_body           113483 non-null object\n",
      "topics_geo          113483 non-null object\n",
      "geo_count           113483 non-null int64\n",
      "topics_count        113483 non-null int64\n",
      "topics_geo_count    113483 non-null int64\n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 10.4+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "### Text\n",
    "\n",
    "We also need to clean the text that contains many special characters indicating a new line, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "record_id\n",
       "455823    A/56/682–S/2001/1159\\n\\nUnited Nations\\n\\nGene...\n",
       "694579    E/2010/SR.46\\n\\nUnited Nations\\n\\nEconomic and...\n",
       "550037    E/2004/SR.47\\n\\nUnited Nations\\n\\nEconomic and...\n",
       "524202    PROVISIONAL\\nE/2003/SR.49\\n28 November 2003\\nO...\n",
       "420454    A/55/257–S/2000/766\\n\\nUnited Nations\\n\\nGener...\n",
       "536496    A/59/PV.65\\n\\nUnited Nations\\n\\nGeneral Assemb...\n",
       "784297    A/68/966–S/2014/573\\n\\nUnited Nations\\n\\nGener...\n",
       "568031    S/2006/113\\n\\nUnited Nations\\n\\nSecurity Counc...\n",
       "502156    A/57/759–S/2003/332\\n\\nUnited Nations\\n\\nGener...\n",
       "563509    S/RES/1645 (2005)\\n\\nUnited Nations\\n\\nSecurit...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace special characters such as new lines with a space.\n",
    "dataset['text'] = dataset['text'].str.replace(r'[\\n\\t\\v]+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "record_id\n",
       "455823    A/56/682–S/2001/1159 United Nations General As...\n",
       "694579    E/2010/SR.46 United Nations Economic and Socia...\n",
       "550037    E/2004/SR.47 United Nations Economic and Socia...\n",
       "524202    PROVISIONAL E/2003/SR.49 28 November 2003 Orig...\n",
       "420454    A/55/257–S/2000/766 United Nations General Ass...\n",
       "536496    A/59/PV.65 United Nations General Assembly Off...\n",
       "784297    A/68/966–S/2014/573 United Nations General Ass...\n",
       "568031    S/2006/113 United Nations Security Council Dis...\n",
       "502156    A/57/759–S/2003/332 United Nations General Ass...\n",
       "563509    S/RES/1645 (2005) United Nations Security Coun...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 113483 entries, 455823 to 273481\n",
      "Data columns (total 11 columns):\n",
      "year                113483 non-null object\n",
      "geo                 54719 non-null object\n",
      "symbol              113483 non-null object\n",
      "title               113483 non-null object\n",
      "topics              112486 non-null object\n",
      "text                113483 non-null object\n",
      "main_body           113483 non-null object\n",
      "topics_geo          113483 non-null object\n",
      "geo_count           113483 non-null int64\n",
      "topics_count        113483 non-null int64\n",
      "topics_geo_count    113483 non-null int64\n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 10.4+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets\n",
    "Using the field main_body, it is possible to create 3 distincts subsets for documents of the Genearal Assembly(A), the Security Council (S), or the Economic and Social Council (E)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "security_council = dataset[dataset['main_body'].str.contains('S')]\n",
    "GA_all = dataset[dataset['main_body'].str.contains('A')]\n",
    "ECOSOC_Council = dataset[dataset['main_body'].str.contains('E')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even create more subsets using the symbol field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First_Committee = dataset[dataset['symbol'].str.contains('A/C.1')]\n",
    "Second_Committee = dataset[dataset['symbol'].str.contains('A/C.2')]\n",
    "Third_Committee = dataset[dataset['symbol'].str.contains('A/C.3')]\n",
    "Fourth_Committee = dataset[dataset['symbol'].str.contains('A/C.4')]\n",
    "Fifth_Committee = dataset[dataset['symbol'].str.contains('A/C.5')]\n",
    "Sixth_Committee = dataset[dataset['symbol'].str.contains('A/C.6')]\n",
    "HR_Council = dataset[dataset['symbol'].str.contains('A/HRC')]\n",
    "GA_Pleanary = GA_all[GA_all['symbol'].str.match('A\\/([1-9]|DEC|RES|BUR|PV|INF|SR|ES-|S-)')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save\n",
    "We can now save our outputs in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('../data/B_engineering/doc_2000_2017.csv')\n",
    "security_council.to_csv('../data/B_engineering/sc_2000_2017.csv')\n",
    "GA_all.to_csv('../data/B_engineering/ga_2000_2017.csv')\n",
    "ECOSOC_Council.to_csv('../data/B_engineering/ecosoc_2000_2017.csv')\n",
    "First_Committee.to_csv('../data/B_engineering/first_2000_2017.csv')\n",
    "Second_Committee.to_csv('../data/B_engineering/second_2000_2017.csv')\n",
    "Third_Committee.to_csv('../data/B_engineering/third_2000_2017.csv')\n",
    "Fourth_Committee.to_csv('../data/B_engineering/fourth_2000_2017.csv')\n",
    "Fifth_Committee.to_csv('../data/B_engineering/fifth_2000_2017.csv')\n",
    "Sixth_Committee.to_csv('../data/B_engineering/sixth_2000_2017.csv')\n",
    "HR_Council.to_csv('../data/B_engineering/hrc_2000_2017.csv')\n",
    "GA_Pleanary.to_csv('../data/B_engineering/ga_plen_2000_2017.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
