{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A - 3 - Dataset Preparation\n",
    "\n",
    "**Process aim:** cleaning the dataset and reduce it to data used for machine learning.\n",
    "\n",
    "**Input:** a CSV containing metadata and full text\n",
    "\n",
    "**Subprocesses:**\n",
    "* import and explore the dataset\n",
    "* normalize fields containing multiple values\n",
    "* drop unwanted columns and rows\n",
    "* add columns\n",
    "* drop rows\n",
    "**Output:** a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and explore the dataset\n",
    "\n",
    "We create a dataframe from the CSV. Dataframes These table-like structures that are easy to manipulation and analyze. \n",
    "\n",
    "* Get information about the dataset such as number of entries (rows), columns names, number of non-null value by columns, etc.\n",
    "    * dataset.info()\n",
    "* Get the name of columns:\n",
    "    * dataset.columns\n",
    "* Get the x first rows of the table, including the headers: \n",
    "    * dataset.head(x)\n",
    "* Get some analytics regarding the dataset or specific columns:\n",
    "    * dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe\n",
    "# We don't need the column with the url anymore\n",
    "columns = ['record_id','body', 'date', 'session', 'subjects_geo','subjects_primary', 'subjects_topics', 'symbol', 'title', \n",
    "           'type','text']\n",
    "dataset = pd.read_csv('data/A_input_data/metadata/output/doc_2000_2017_txt.csv',index_col='record_id',usecols=columns, dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out records with missing data\n",
    "dataset = dataset[dataset.symbol.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using dataset.info() we can see for each field how many are non-null values. For instance, how many records have subject-topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize 'date'\n",
    "To be able to sorg and group by date, we need to ensure that the date is normalized and that all rows have a value. Because this field is not always filled or a complete date, we need to normalize it, as follow:\n",
    "* use the year instead of the full date\n",
    "* fill the gaps with the previous value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['date'] = (dataset.date\n",
    "                   .str.extract('(\\d{4})',expand=False) #  extract the first 4 digits corresponding to the year\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out unwanted data\n",
    "dataset = dataset[dataset['date'].notnull()]\n",
    "dataset = dataset[dataset['date'] != '1999']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check our dataset to ensure the date field has a value for each record\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Rename column 'date' to year\n",
    "dataset = dataset.rename(columns={'date':'year'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize 'body':\n",
    "Annother usefull sorting option is by body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_body(line):\n",
    "    '''\n",
    "    Clean multiple value cells to return multiple values to return each line:\n",
    "    - fields with multiple values: value one||value two\n",
    "    - fields with a single value: value one\n",
    "    '''\n",
    "    if isinstance(line, str):\n",
    "        line = re.sub(\"(\\*+)|\\'|\\[|\\]|\\s+\",\"\",line)\n",
    "        line = line.split(',')\n",
    "        line = [body.split(\"/\")[0] for body in line]\n",
    "        line = [body for body in line if body in ['A','S','E']]\n",
    "        line = filter(None, line)\n",
    "        line = list(set(line))\n",
    "        line = re.sub(\"(\\*+)|\\'|\\[|\\]|\\s+\",\"\",str(line))\n",
    "        return line\n",
    "    else:\n",
    "        return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['main_body'] = dataset['body'].apply(normalize_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.main_body.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['main_body'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize fields containing multiple values\n",
    "\n",
    "Some columns have multiple values into square brackets, we want to normalize these colums as follow:\n",
    "* fields with multiple values: value one||value two\n",
    "* fields with a single value: value one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_multiple(line):\n",
    "    '''\n",
    "    Clean multiple value cells to return multiple values to return each line:\n",
    "    - fields with multiple values: value one||value two\n",
    "    - fields with a single value: value one\n",
    "    '''\n",
    "    if isinstance(line, str):\n",
    "        if line.startswith('['):\n",
    "            line = re.sub(\"\\[|\\]\",\"\",line)\n",
    "            line = line.strip(\"'\")\n",
    "            line = line.strip('\"')\n",
    "            line = line.strip(\" \")\n",
    "            line = re.sub(\"('|\\\"),\\s?('|\\\")\",\"||\",line)\n",
    "            return line\n",
    "        else:\n",
    "            line = line.strip(\"'\")\n",
    "            line = line.strip('\"')\n",
    "            line = line.strip(\" \")\n",
    "            line = re.sub(\"\\*\",\"\",line)\n",
    "            return line\n",
    "    else:\n",
    "        return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['subjects_geo'] = dataset['subjects_geo'].apply(normalize_multiple)\n",
    "dataset['subjects_topics'] = dataset['subjects_topics'].apply(normalize_multiple)\n",
    "dataset['subjects_primary'] = dataset['subjects_primary'].apply(normalize_multiple)\n",
    "dataset['symbol'] = dataset['symbol'].apply(normalize_multiple)\n",
    "dataset['type'] = dataset['type'].apply(normalize_multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text field\n",
    "\n",
    "Clean special characters like new line (\\n), tabs (\\t) etc. in 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace special characters such as new lines with a space.\n",
    "dataset['text'] = dataset['text'].str.replace(r'[\\n\\t\\v]+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('data/A_input_data/metadata/output/doc_2000_2017_txt_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
